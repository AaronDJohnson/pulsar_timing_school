{
 "metadata": {
  "name": "",
  "signature": "sha256:5edbfd8f6722877c78da3e0e506679c58df3398492857b7c1564a01bd6018909"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Sampling Continuous Wave Signals"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import numpy as np\n",
      "import scipy.linalg as sl\n",
      "import scipy.special as ss\n",
      "import matplotlib.pyplot as plt\n",
      "from PAL2 import bayesutils as bu\n",
      "import os, sys, glob\n",
      "import simple_mcmc as smcmc\n",
      "from ptmcmc import PTMCMC\n",
      "import scipy.constants as sc\n",
      "\n",
      "%matplotlib inline\n",
      "%config InlineBackend.figure_format = 'retina'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "day = 86400.0                   # Seconds per day\n",
      "year =  31557600.0              # Seconds per year (yr = 365.25 days, so Julian years)\n",
      "mjdT0 = 54000.0                 # MJD to which all toas are referenced (for precision)\n",
      "\n",
      "SOLAR2S = sc.G / sc.c**3 * 1.98855e30\n",
      "KPC2S = sc.parsec / sc.c * 1e3\n",
      "MPC2S = sc.parsec / sc.c * 1e6"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def designqsd(t, order=2):\n",
      "    \"\"\"\n",
      "    Calculate the design matrix for quadratic spindown\n",
      "\n",
      "    :param t:\n",
      "        array of toas\n",
      "    \"\"\"\n",
      "    M = np.ones([len(t), order+1])\n",
      "    for ii in range(1, order+1):\n",
      "        M[:,ii] = t ** ii\n",
      "    \n",
      "    return M.copy()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def createAntennaPatternFuncs(psr, gwtheta, gwphi):\n",
      "    \"\"\"\n",
      "    Function to create pulsar antenna pattern functions as defined\n",
      "    in Ellis, Siemens, and Creighton (2012).\n",
      "\n",
      "    :param psr: pulsar object for single pulsar\n",
      "    :param gwtheta: GW polar angle in radians\n",
      "    :param gwphi: GW azimuthal angle in radians\n",
      "\n",
      "    :return: (fplus, fcross, cosMu), where fplus and fcross\n",
      "             are the plus and cross antenna pattern functions\n",
      "             and cosMu is the cosine of the angle between the \n",
      "             pulsar and the GW source.\n",
      "    \"\"\"\n",
      "\n",
      "    # use definition from Sesana et al 2010 and Ellis et al 2012\n",
      "    m = np.array([-np.sin(gwphi), np.cos(gwphi), 0.0])\n",
      "    n = np.array([-np.cos(gwtheta)*np.cos(gwphi), -np.cos(gwtheta)*np.sin(gwphi),\n",
      "                  np.sin(gwtheta)])\n",
      "    omhat = np.array([-np.sin(gwtheta)*np.cos(gwphi), -np.sin(gwtheta)*np.sin(gwphi),\n",
      "                      -np.cos(gwtheta)])\n",
      "\n",
      "    phat = np.array([np.sin(psr.theta)*np.cos(psr.phi), np.sin(psr.theta)*np.sin(psr.phi),\n",
      "                     np.cos(psr.theta)])\n",
      "\n",
      "    fplus = 0.5 * (np.dot(m, phat)**2 - np.dot(n, phat)**2) / (1+np.dot(omhat, phat))\n",
      "    fcross = (np.dot(m, phat)*np.dot(n, phat)) / (1 + np.dot(omhat, phat))\n",
      "    cosMu = -np.dot(omhat, phat)\n",
      "\n",
      "    return fplus, fcross, cosMu"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def createResiduals(psr, gwtheta, gwphi, h, fgw, phase0, psi, inc):\n",
      "    \"\"\"\n",
      "    Function to create GW incuced residuals from a SMBMB as \n",
      "    defined in Ellis et. al 2012,2013.\n",
      "\n",
      "    :param psr: pulsar object for single pulsar\n",
      "    :param gwtheta: Polar angle of GW source in celestial coords [radians]\n",
      "    :param gwphi: Azimuthal angle of GW source in celestial coords [radians]\n",
      "    :param h: GW strain amplitude\n",
      "    :param fgw: Frequency of GW (twice the orbital frequency) [Hz]\n",
      "    :param phase0: Initial Phase of GW source [radians]\n",
      "    :param psi: Polarization of GW source [radians]\n",
      "    :param inc: Inclination of GW source [radians]\n",
      "\n",
      "    :return: Vector of induced residuals\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    # get antenna pattern funcs and cosMu\n",
      "    fplus, fcross, cosMu = createAntennaPatternFuncs(psr, gwtheta, gwphi)\n",
      "    \n",
      "    # get values from pulsar object\n",
      "    toas = psr.toas\n",
      "\n",
      "    # orbital frequency\n",
      "    w0 = np.pi * fgw\n",
      "    phase0 /= 2 # orbital phase\n",
      "      \n",
      "    # monochromatic\n",
      "    omega = np.pi * fgw\n",
      "    phase = phase0 + omega * toas\n",
      "        \n",
      "    # define time dependent coefficients\n",
      "    At = -0.5 * np.sin(2*phase) * (3+np.cos(2*inc))\n",
      "    Bt = 2 * np.cos(2*phase) * np.cos(inc)\n",
      "\n",
      "    # now define amplitude \n",
      "    alpha = 0.5 * h / omega\n",
      "\n",
      "    # define rplus and rcross\n",
      "    rplus = alpha * (At*np.cos(2*psi) - Bt*np.sin(2*psi))\n",
      "    rcross = alpha * (At*np.sin(2*psi) + Bt*np.cos(2*psi))\n",
      "\n",
      "    res = -fplus*rplus - fcross*rcross\n",
      "\n",
      "    return res"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def createRmatrix(designmatrix, err):\n",
      "    \"\"\"\n",
      "    Create R matrix as defined in Ellis et al (2013) and Demorest et al (2012)\n",
      "\n",
      "    :param designmatrix: Design matrix as returned by tempo2\n",
      "\n",
      "    :return: R matrix \n",
      "   \n",
      "    \"\"\"\n",
      "\n",
      "    W = np.diag(1/err)\n",
      "    w = 1/err\n",
      "\n",
      "    u, s, v = sl.svd((w * designmatrix.T).T,full_matrices=False)\n",
      "\n",
      "    return np.eye(len(err)) - (1/w * np.dot(u, np.dot(u.T, W)).T).T "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Pulsar(object):\n",
      "    \n",
      "    def __init__(self, toas, residuals, toaerrs, theta, phi,\n",
      "                 desmat=None, nfreqs=20, qsdorder=2, Tlow=None):\n",
      "        \"\"\"\n",
      "        Initialise the pulsar from data\n",
      "\n",
      "        :param toas:\n",
      "            The barycentric times of arrival [MJD]\n",
      "\n",
      "        :param residuals:\n",
      "            The timing residuals [sec]\n",
      "\n",
      "        :param toaerrs:\n",
      "            The TOA uncertainties [sec]\n",
      "            \n",
      "        :param theta:\n",
      "            Polar angle of pulsar (pi/2 - declination)\n",
      "            \n",
      "        :param phi:\n",
      "            Azimuthal angle of pulsar (same as ra)\n",
      "\n",
      "        :param desmat:\n",
      "            The design matrix (default None)\n",
      "\n",
      "        :param qsdorder:\n",
      "            If desmat=None, make a design matrix from scratch, with this order\n",
      "    \"\"\"\n",
      "        \n",
      "        self.toas = (toas - mjdT0) * day       # MJD to seconds\n",
      "        self.residuals = residuals\n",
      "        self.toaerrs = toaerrs\n",
      "        self.Mmat = desmat\n",
      "        self.nobs = len(toas)\n",
      "        self.nfreqs = nfreqs\n",
      "        self.theta = theta\n",
      "        self.phi = phi\n",
      "\n",
      "        self.T = (np.max(self.toas) - np.min(self.toas))\n",
      "\n",
      "        if self.Mmat is None:\n",
      "            self.Mmat = designqsd(self.toas, order=qsdorder)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_pta_data(N=6, T=10, ntoa=200, sigma=1e-7, gwtheta=1.3, \n",
      "                  gwphi=3.1, h=5e-15, fgw=1.0e-8, phase0=np.pi/3,\n",
      "                  psi=np.pi/2, inc=np.pi/4):\n",
      "\n",
      "    psr = []\n",
      "    for ii in range(N):\n",
      "\n",
      "        # sky location\n",
      "        theta = np.arccos(np.random.uniform(-1, 1))\n",
      "        phi = np.random.uniform(0, 2*np.pi)\n",
      "\n",
      "        # TOAs\n",
      "        t = np.linspace(mjdT0, mjdT0 + 365.25 * T, ntoa)\n",
      "\n",
      "        # toa errors\n",
      "        toaerrs = np.ones(ntoa) * sigma\n",
      "\n",
      "        # design matrix\n",
      "        M = designqsd(t)\n",
      "\n",
      "        # R matrix\n",
      "        R = createRmatrix(M, toaerrs)\n",
      "\n",
      "        # noise\n",
      "        res = np.random.randn(ntoa) * toaerrs\n",
      "\n",
      "        # fill in pulsar class\n",
      "        psr.append(Pulsar(t, res, toaerrs, theta, phi, desmat=M))\n",
      "\n",
      "        # add cgw\n",
      "        res += createResiduals(psr[-1], gwtheta, gwphi, h, fgw, phase0, psi, inc)\n",
      "\n",
      "        # fit\n",
      "        psr[-1].residuals = np.dot(R, res)\n",
      "        \n",
      "    return psr\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exercise 1: Creating fake data\n",
      "\n",
      "This is a simple exercise to simulate some fake data using the functions above.\n",
      "\n",
      "1. Use the ``make_pta_data`` function above to constuct a PTA with 6 pulsars timed for 10 years with 100 ns RMS. Furthermore inject a GW with $(\\theta, \\phi, h, f_{gw}, \\Phi_0, \\psi, \\iota)=(1.3, 3.1, 5\\times 10^{-15}, 10^{-8} Hz, \\pi/3, \\pi/4)$\n",
      "2. Plot each set of residuals."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exercise 2: Writing the Likelihood\n",
      "\n",
      "Here you will construct a likelihood function for CW sources. This will be very similar to the likelihood from Day2 but here we will assume that the noise parameters are known and will only deal with white measurement noise.\n",
      "\n",
      "The likelihood that you will construct is:\n",
      "\n",
      "$$p(\\delta t | \\lambda) = \\frac{\\exp\\left[-\\frac{1}{2}((\\delta\\mathbf{t}-s(\\lambda))^{T}N^{-1}(\\delta\\mathbf{t}-s(\\lambda)) - \\mathbf{d}^{T}\\Sigma^{-1}\\mathbf{d})  \\right]}\n",
      "{\\sqrt{\\det(N) \\det(\\Sigma)}},$$\n",
      "\n",
      "where in this case \n",
      "\n",
      "$$\\Sigma = T^TN^{-1}T$$\n",
      "\n",
      "$$ d = T^T N^{-1}(\\delta\\mathbf{t}-s(\\lambda))$$\n",
      "\n",
      "and $s(\\lambda)$ is the GW waveform parameters by a set of parameters $\\lambda$.\n",
      "\n",
      "1. Use the `createResiduals` function to calculate the GW waveform given a set of free parametes. The easiest way to compute the full PTA likelihood is to loop over the pulsars and compute the ln-likelihood for each and then sum them in the end. Furthermore, it is easiest if you make a `class` for this so that you can store the product $T^TN^{-1}T$ so that you won't have to do that matrix product every time. \n",
      "\n",
      "2. In addition to a likeihood function. Also create a prior function that makes sure the parameters are in correct range: $\\cos\\theta\\in[-1,1]$, $\\phi\\in[0,2\\pi]$, $\\log_{10} h \\in [-17,-12]$, $\\log_{10}f_{gw}\\in[-7,-9]$, $\\Phi_0\\in[0,2\\pi]$, $\\psi\\in[0,\\pi]$, and $\\cos\\iota\\in[0,1]$. \n",
      "\n",
      "3. You should use the free parameters $(\\cos\\theta, \\phi, \\log_{10} h, \\log_{10}f_{gw}, \\Phi_0, \\psi, \\cos\\iota)$ this way we can use uniform priors on these parameters."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class SingleGWLikelihood(object):\n",
      "    \n",
      "    def __init__(self, psr):\n",
      "        \n",
      "        self.psr = psr\n",
      "        \n",
      "        # auxiliary quantities\n",
      "        for ct, p in enumerate(self.psr):\n",
      "            p.Nvec = p.toaerrs**2\n",
      "            p.Tmat = p.Mmat.copy()\n",
      "            \n",
      "            # store T^TN^{-1}T\n",
      "            right = ((1 / p.Nvec) * p.Tmat.T).T\n",
      "            p.TNT = np.dot(p.Tmat.T, right)\n",
      "    \n",
      "    def lnlikefn(self, x):\n",
      "        \n",
      "        # get parameters\n",
      "\n",
      "        \n",
      "        loglike = 0\n",
      "        #for ct, p in enumerate(self.psr):\n",
      "            \n",
      "            # add log-likelihood for each pulsar\n",
      "            \n",
      "        return loglike\n",
      "    \n",
      "    def lnpriorfn(self, x):\n",
      "        \n",
      "        pmin = np.array([-1, 0, -17, -9, 0, 0, 0])\n",
      "        pmax = np.array([1, 2*np.pi, -12, -7, 2*np.pi, np.pi, 1])\n",
      "        \n",
      "        if np.all(x < pmax) and np.all(x > pmin):\n",
      "            return np.sum(1 / (pmax-pmin))\n",
      "        else:\n",
      "            return -np.inf\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exercise 3.1: Parameter estimation: MCMC sampling of CW signal.\n",
      "\n",
      "1. Run your (or the provided) MCMC on your simulated dataset. A good choice of jump sizes is `sigmas = np.array([0.1, 0.1, 0.1, 0.001, 0.1, 0.1, 0.1])`. Run your MCMC for 100000 iterations.\n",
      "2. Plot the chain trace and histogram for each GW parameter along with an indicator (i.e vertical or horizontal line) of the injected value.\n",
      "3. Plot the triangle plot.\n",
      "4. Did you recover the injected values? What do you notice about the correlations of parameters.\n",
      "5. Plot the injected waveform for one pulsar. Then overplot 1000 waveforms constructed from your MCMC chain. Use the `alpha=0.1` argument of `plot` to make this more visible."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exercise 3.2: A bit of help...\n",
      "\n",
      "As you maybe noticed, you didn't recover the correct parameters in the last run.\n",
      "\n",
      "This is because our simple sampler only uses one type of jump and it cannot explore the large parameter space \n",
      "very efficiently if it starts far from the High Probablility Region (HPR)\n",
      "\n",
      "To ameliorate this problem, start the MCMC sampler at the injected value of the frequency. In Principle we could just start at the injected values for all of the parameters but at least in this case we do have more simple algorithms for estimating the frequency so this exercise is not all that contrived.\n",
      "\n",
      "Repeat exercise 3.1 again for this new starting position."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Exercise 3.3: Bringing out the big guns...\n",
      "\n",
      "Even starting the MCMC sampler at the injected values of the frequency and amplitude does not lead to great exploration of the parameter space and it can still get stuck in secondary maxima.\n",
      "\n",
      "There are many solutions to this problem including more compicated jump proposals. Another approach is to still use our simple gaussian jump proposals but to use parallel tempering to more efficiently explore the parameter space.\n",
      "\n",
      "1. Use the PTMCMC sampler provided (or your own if you have it). Run 10 temperature chains with spacing (this is automatic if you use the provided sampler)\n",
      "\n",
      "$$dT = 1 + \\sqrt{\\frac{2}{n_{\\rm dim}}}$$\n",
      "\n",
      "2. Start each temperature chain at a random position in parameters space.\n",
      "3. Repeat the steps of Exercise 3.1.\n",
      "\n",
      "What is different between this run and the last? Does it map out the parameter space better?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ndim = 7\n",
      "ntemp = 10\n",
      "N = 100000\n",
      "pmin = np.array([-1, 0, -17, -9, 0, 0, 0])\n",
      "pmax = np.array([1, 2*np.pi, -11, -7, 2*np.pi, np.pi, 1])\n",
      "p0 = np.random.uniform(low=pmin, high=pmax, size=(ntemp, ndim))\n",
      "sigmas = np.array([0.1, 0.1, 0.1, 0.001, 0.1, 0.1, 0.1])\n",
      "\n",
      "#initialize likelihood and sampler and run"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exercise 4: Bayesian Upper Limits\n",
      "\n",
      "In the previous exercises you have carried out parameter estimation of a real signal in the data. With our current level of sensitivity in pulsar timing we have no GW signals to parameterize. What we do is we try to set upper limits on a subset of these parameters.\n",
      "\n",
      "In this exercise you will create a dataset containing only noise and will place upper limits on the strain amplitude as a function of GW frequency.\n",
      "\n",
      "Create a dataset identical to the one above but this time set $h=10^{-18}$ which is essentially 0 in our case. Plot the residuals for each pulsar."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exercise 4.1: Computing the upper limit\n",
      "\n",
      "Previously we had used a log-uniform prior for the GW strain amplitude. To compute upper limits however you will need to use a *uniform* prior on the GW amplitude to set upper limits.\n",
      "\n",
      "However, the GW amplitude will still range over several orders of magnitude and it turns out that it is still easier to *sample* in $\\log_{10}h$ but with a prior that is uniform in $h$.\n",
      "\n",
      "1. What should the prior be on $\\log_{10}h$ if we desire a prior uniform in $h$? Remember that the probability densities are eaual.\n",
      "$$p(\\log_{10}h)d\\log_{10}h = p(h)dh$$\n",
      "\n",
      "2. Why is it improper to use a log-uniform prior for upper limits?\n",
      "\n",
      "3. Once you have the new prior set, run the standard sampler on your white noise dataset for 500000 samples. Again repeat the steps of exercise 3.1."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exercise 4.2: Make the plot\n",
      "\n",
      "Here you can make the plot of the strain upper limit as a function of GW frequency using the `bayesutils` function `upperlimit2d`. You should give it the optional `log=True` and `bins=100` options.\n",
      "\n",
      "Just to give you an idea, what this function does is it bins the frequencies and computes upper limit on the strain amplitude for each frequency bin. In production level runs, we would hold the GW frequency fixed and compute the upper limit for each frequency but this binning method is sufficient for this exercise.\n",
      "\n",
      "Why do the upper limits have this shape?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    }
   ],
   "metadata": {}
  }
 ]
}